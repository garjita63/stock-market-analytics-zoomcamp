{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEM4xIzPm4VFXasPXq074F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garjita63/stock-market-analytics-zoomcamp/blob/main/homework_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution of Question 1"
      ],
      "metadata": {
        "id": "23wyTNDt9TQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "# Define function to extract price from \"Price Range\" string\n",
        "def extract_price(price_range):\n",
        "  if pd.isna(price_range):\n",
        "    return None\n",
        "  elif \"-\" not in price_range:\n",
        "    # Remove leading/trailing spaces and dollar sign ($) before conversion (handle empty string)\n",
        "    price_without_symbol = price_range.strip(\" $\")\n",
        "    return float(price_without_symbol) if price_without_symbol else None\n",
        "  else:\n",
        "    prices = price_range.split(\"-\")\n",
        "    # Check if both prices are valid before converting and calculating average\n",
        "    if all(price.strip(\" $\") for price in prices):\n",
        "      return (float(prices[0].strip(\" $\")) + float(prices[1].strip(\" $\"))) / 2\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "\n",
        "url = \"https://stockanalysis.com/ipos/filings/\"\n",
        "response = requests.get(url)\n",
        "\n",
        "filings_dfs = pd.read_html(response.text)\n",
        "\n",
        "filings_df = filings_dfs[0]\n",
        "\n",
        "# Convert 'Filing Date' to datetime\n",
        "filings_df['Filing Date'] = pd.to_datetime(filings_df['Filing Date'])\n",
        "\n",
        "# Convert 'Shares Offered' to float\n",
        "filings_df['Shares Offered'] = pd.to_numeric(filings_df['Shares Offered'].str.replace(',', ''), errors='coerce')\n",
        "\n",
        "# Define 'Avg_price' column\n",
        "filings_df['Avg_price'] = filings_df['Price Range'].apply(extract_price)\n",
        "\n",
        "# Calculate 'Shares_offered_value'\n",
        "filings_df['Shares_offered_value'] = filings_df['Shares Offered'] * filings_df['Avg_price']\n",
        "\n",
        "# Filter for 2023 filings on Fridays\n",
        "friday_filings_2023 = filings_df[(filings_df['Filing Date'].dt.year == 2023) & (filings_df['Filing Date'].dt.dayofweek == 4)]\n",
        "\n",
        "# Calculate total sum in millions (round to nearest integer)\n",
        "total_sum_millions = round(friday_filings_2023['Shares_offered_value'].dropna().sum() / 1e6, 0)\n",
        "\n",
        "print(f\"Total sum of 2023 filings on Fridays ($m): {total_sum_millions}\")\n",
        "\n",
        "# Additional info - Check for expected number of records\n",
        "print(f\"Total number of records: {len(filings_df)}\")\n",
        "print(f\"Number of records with non-null 'Shares_offered_value' on Fridays in 2023: {len(friday_filings_2023)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdRQXOownux3",
        "outputId": "e5719460-5456-42a6-9922-1474ca8a591b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sum of 2023 filings on Fridays ($m): 276.0\n",
            "Total number of records: 329\n",
            "Number of records with non-null 'Shares_offered_value' on Fridays in 2023: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer of Question 1 : 276"
      ],
      "metadata": {
        "id": "GOcbbNg19Gw5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqc5JhdI9GMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution of Question 2"
      ],
      "metadata": {
        "id": "ELzvUQ4sXA7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Retrieve IPO data for 2023 and 2024\n",
        "ipo_urls = [\"https://stockanalysis.com/ipos/2023/\", \"https://stockanalysis.com/ipos/2024/\"]\n",
        "ipo_dfs = []\n",
        "\n",
        "for url in ipo_urls:\n",
        "    response = requests.get(url)\n",
        "    ipo_dfs.append(pd.read_html(response.text)[0])\n",
        "\n",
        "ipo_df = pd.concat(ipo_dfs).reset_index(drop=True)\n",
        "\n",
        "# Convert 'IPO Date' to datetime without warning\n",
        "ipo_df['IPO Date'] = pd.to_datetime(ipo_df['IPO Date']).copy()\n",
        "\n",
        "# Filter IPOs before March 1, 2024\n",
        "ipo_df = ipo_df[ipo_df['IPO Date'] < '2024-03-01']\n",
        "\n",
        "# Get ticker symbols\n",
        "ticker_symbols = ipo_df['Symbol'].tolist()\n",
        "\n",
        "# Remove ticker symbol of RYZB\n",
        "ticker_symbols.remove('RYZB')\n",
        "\n",
        "# Adjust ticker symbols if needed\n",
        "ticker_adjustments = {'IBAC': 'IBACU', 'PTHR': 'PTHRF'} # Add adjustments as needed\n",
        "for i, symbol in enumerate(ticker_symbols):\n",
        "    if symbol in ticker_adjustments:\n",
        "        ticker_symbols[i] = ticker_adjustments[symbol]\n",
        "\n",
        "\n",
        "# Get OHLCV data for each ticker\n",
        "start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')  # 1 year of data\n",
        "end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "prices = yf.download(ticker_symbols, start=start_date, end=end_date)\n",
        "\n",
        "# Calculate growth for each holding period\n",
        "holding_periods = range(1, 31)\n",
        "growth_data = {}\n",
        "\n",
        "for ticker in ticker_symbols:\n",
        "    try:\n",
        "        for days in holding_periods:\n",
        "            initial_price = prices['Adj Close'][ticker].iloc[0]\n",
        "            final_price = prices['Adj Close'][ticker].iloc[days]\n",
        "            growth = (final_price - initial_price) / initial_price\n",
        "            if (ticker, days) not in growth_data:\n",
        "                growth_data[(ticker, days)] = []\n",
        "            growth_data[(ticker, days)].append(growth)\n",
        "    except KeyError:\n",
        "        print(f\"No data found for ticker: {ticker}\")\n",
        "\n",
        "# Create DataFrame from growth data\n",
        "rows = []\n",
        "for key, values in growth_data.items():\n",
        "    for value in values:\n",
        "        rows.append((key[0], key[1], value))\n",
        "growth_df = pd.DataFrame(rows, columns=['Ticker', 'Days', 'Growth'])\n",
        "\n",
        "# Calculate 75% quantile growth for each X\n",
        "quantile_75 = growth_df.groupby('Days')['Growth'].quantile(0.75)\n",
        "\n",
        "# Find X where 75% quantile growth is highest\n",
        "optimal_X = quantile_75.idxmax()\n",
        "highest_growth = quantile_75.max()\n",
        "# optimal_X, highest_growth\n",
        "\n",
        "print (\"\\nThe optimal number of days X (between 1 and 30), where 75% quantile growth is the highest : \", optimal_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhiHYnWQVFyC",
        "outputId": "85b33991-b75d-413f-f05b-645c51ae094f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  184 of 184 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The optimal number of days X (between 1 and 30), where 75% quantile growth is the highest :  29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer of Question 2 : 29"
      ],
      "metadata": {
        "id": "GRbDbdJc9ijB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution of Question 3"
      ],
      "metadata": {
        "id": "_s0eqQeI6MFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "US_STOCKS = ['MSFT', 'AAPL', 'GOOG', 'NVDA', 'AMZN', 'META', 'BRK-B', 'LLY', 'AVGO', 'V', 'JPM']\n",
        "EU_STOCKS = ['NVO', 'MC.PA', 'ASML', 'RMS.PA', 'OR.PA', 'SAP', 'ACN', 'TTE', 'SIE.DE', 'IDEXY', 'CDI.PA']\n",
        "INDIA_STOCKS = ['RELIANCE.NS', 'TCS.NS', 'HDB', 'BHARTIARTL.NS', 'IBN', 'SBIN.NS', 'LICI.NS', 'INFY', 'ITC.NS', 'HINDUNILVR.NS', 'LT.NS']\n",
        "\n",
        "largest_stock = US_STOCKS + EU_STOCKS + INDIA_STOCKS\n",
        "\n",
        "NEW_US = ['TSLA', 'WMT', 'XOM', 'UNH', 'MA', 'PG', 'JNJ', 'MRK', 'HD', 'COST', 'ORCL']\n",
        "NEW_EU = ['PRX.AS', 'CDI.PA', 'AIR.PA', 'SU.PA', 'ETN', 'SNY', 'BUD', 'DTE.DE', 'ALV.DE', 'MDT', 'AI.PA', 'EL.PA']\n",
        "NEW_INDIA = ['BAJFINANCE.NS', 'MARUTI.NS', 'HCLTECH.NS', 'TATAMOTORS.NS', 'SUNPHARMA.NS', 'ONGC.NS', 'ADANIENT.NS', 'ADANIENT.NS', 'NTPC.NS', 'KOTAKBANK.NS', 'TITAN.NS']\n",
        "\n",
        "large_stock = NEW_EU + NEW_US + NEW_INDIA\n",
        "\n",
        "# Now all_stocks includes both LARGEST & LARGE STOCKS\n",
        "all_stocks = largest_stock + large_stock\n",
        "\n",
        "# Download OHLCV data for all stocks for 10 years\n",
        "start_date = '2014-01-01'\n",
        "end_date = '2023-12-31'\n",
        "data_largest = yf.download(largest_stock, start=start_date, end=end_date)\n",
        "data_large = yf.download(large_stock, start=start_date, end=end_date)\n",
        "data = yf.download(all_stocks, start=start_date, end=end_date)\n",
        "\n",
        "## Largest data\n",
        "# Calculate daily growth for the last 7 days for each stock\n",
        "def calculate_growth_7d_largest(data_largest):\n",
        "    return data_largest['Adj Close'].pct_change(7)  # Calculate pct change for last 7 days\n",
        "\n",
        "# Calculate 7-day growth for all stocks using vectorized operations\n",
        "growth_7d_largest = calculate_growth_7d_largest(data_largest)\n",
        "\n",
        "# Combine the 'growth_7d' data with the DataFrame\n",
        "growth_7d_largest.columns = pd.MultiIndex.from_product([['growth_7d_largest'], growth_7d_largest.columns])\n",
        "data_largest = pd.concat([data_largest, growth_7d_largest], axis=1)\n",
        "\n",
        "## Large data\n",
        "# Calculate daily growth for the last 7 days for each stock\n",
        "def calculate_growth_7d_large(data_large):\n",
        "    return data_large['Adj Close'].pct_change(7)  # Calculate pct change for last 7 days\n",
        "\n",
        "# Calculate 7-day growth for all stocks using vectorized operations\n",
        "growth_7d_large = calculate_growth_7d_large(data_large)\n",
        "\n",
        "# Combine the 'growth_7d' data with the DataFrame\n",
        "growth_7d_large.columns = pd.MultiIndex.from_product([['growth_7d_large'], growth_7d_large.columns])\n",
        "data_large = pd.concat([data_large, growth_7d_large], axis=1)\n",
        "\n",
        "## All data\n",
        "# Calculate daily growth for the last 7 days for each stock\n",
        "def calculate_growth_7d(data):\n",
        "    return data['Adj Close'].pct_change(7)  # Calculate pct change for last 7 days\n",
        "\n",
        "# Calculate 7-day growth for all stocks using vectorized operations\n",
        "growth_7d = calculate_growth_7d(data)\n",
        "\n",
        "# Combine the 'growth_7d' data with the DataFrame\n",
        "growth_7d.columns = pd.MultiIndex.from_product([['growth_7d'], growth_7d.columns])\n",
        "data = pd.concat([data, growth_7d], axis=1)\n",
        "\n",
        "\n",
        "# Calculate average daily growth for Largest and Large stocks\n",
        "try:\n",
        "    daily_growth_largest = data_largest['growth_7d_largest'].mean(axis=1)\n",
        "    daily_growth_large = data_large['growth_7d_large'].mean(axis=1)\n",
        "\n",
        "    # Calculate the number of days when Large outperforms Largest\n",
        "    outperformance_days = (daily_growth_large > daily_growth_largest).sum()\n",
        "\n",
        "    # Get the total number of trading days\n",
        "    total_days = len(daily_growth_large)\n",
        "\n",
        "    # Calculate the percentage of days Large outperforms Largest (rounded to nearest integer)\n",
        "    percentage_outperformance = int((outperformance_days / total_days) * 100)\n",
        "    print(f\"\\nLarge stocks outperformed Largest stocks on approximately {percentage_outperformance}% of days.\")\n",
        "\n",
        "except KeyError:\n",
        "    print(\"Error: 'growth_7d' column not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK8nbrdjszIT",
        "outputId": "ac1a13ef-7243-4619-b9f6-1e770da7e341"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  33 of 33 completed\n",
            "[*********************100%%**********************]  33 of 33 completed\n",
            "[*********************100%%**********************]  65 of 65 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Large stocks outperformed Largest stocks on approximately 46% of days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer of Question 3: 46"
      ],
      "metadata": {
        "id": "u8cKN44o9oTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution of Question 4\n",
        "**See continue of Module2_Colab_Working_with_the_data.ipynb (after Code snippet 9)**\n",
        "\n",
        "Answer of Question 4 : 2"
      ],
      "metadata": {
        "id": "VRLIr4vu4PWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution of Question 5"
      ],
      "metadata": {
        "id": "OudokC2Y4XRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refining the Approach to IPO Investing\n",
        "Since simply investing in all IPOs isn't a winning strategy, here's how we can refine our approach:\n",
        "\n",
        "1. Focus on Specific Verticals:\n",
        "\n",
        "Data: Look for historical IPO data that includes the company's industry sector (verticals). Sources like telecommunications, financial websites or market research firms might offer this data.\n",
        "Analysis: Analyze which industry sectors have a higher success rate (positive returns for investors post-IPO). This could involve calculating average returns by sector over a specific period.\n",
        "2. Smart Comparison with Existing Stocks:\n",
        "\n",
        "Data: We'll need financial data for both IPO companies and their established competitors. This data could include metrics like Price-to-Earnings (P/E) ratio, revenue growth, and market capitalization. Public financial databases or financial news websites can be sources for this data.\n",
        "Analysis: Compare the valuation (e.g., P/E ratio) of the IPO company to its established competitors. Look for companies with a strong track record, but a lower valuation than their peers. This might indicate higher future growth potential for the IPO.\n",
        "3. Focus on Company Fundamentals (beyond size):\n",
        "\n",
        "Data: Look for IPO prospectuses, financial statements, and news articles. These can provide insights into the company's:\n",
        "Revenue and Profit Growth: Look for companies with consistent and sustainable growth in revenue and profits.\n",
        "Market Opportunity: Analyze the total addressable market (TAM) for the company's product or service. A large and growing TAM indicates significant potential for future growth.\n",
        "Competitive Advantage: Does the company have a strong moat, a competitive edge that protects it from rivals? This could be brand recognition, intellectual property, or a unique technology.\n",
        "Management Team: Evaluate the experience and track record of the management team. A strong leadership team is crucial for navigating future challenges and growth.\n",
        "Bypassing \"Total Number of People\":\n",
        "\n",
        "While the total number of employees might be interesting, it's not a strong indicator of a successful IPO. Instead, focusing on the quality and experience of the team is more relevant."
      ],
      "metadata": {
        "id": "fvot1B6I6a0V"
      }
    }
  ]
}