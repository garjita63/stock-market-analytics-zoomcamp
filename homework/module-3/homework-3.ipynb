{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ge4C2c2_w7Ac"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AsPVf4XT1JAZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_7d</th>\n",
       "      <th>growth_brent_oil_30d</th>\n",
       "      <th>growth_brent_oil_90d</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.060163</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>3.081600e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>1.331712e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>6.776640e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.098090</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>4.789440e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close_x        Volume Ticker  \\\n",
       "0  0.088542  0.101563  0.088542  0.097222     0.060163  1.031789e+09   MSFT   \n",
       "1  0.097222  0.102431  0.097222  0.100694     0.062311  3.081600e+08   MSFT   \n",
       "2  0.100694  0.103299  0.100694  0.102431     0.063386  1.331712e+08   MSFT   \n",
       "3  0.102431  0.103299  0.098958  0.099826     0.061774  6.776640e+07   MSFT   \n",
       "4  0.099826  0.100694  0.097222  0.098090     0.060700  4.789440e+07   MSFT   \n",
       "\n",
       "   Year      Month  Weekday  ... growth_brent_oil_7d  growth_brent_oil_30d  \\\n",
       "0  1986 1986-03-01        3  ...                 NaN                   NaN   \n",
       "1  1986 1986-03-01        4  ...                 NaN                   NaN   \n",
       "2  1986 1986-03-01        0  ...                 NaN                   NaN   \n",
       "3  1986 1986-03-01        1  ...                 NaN                   NaN   \n",
       "4  1986 1986-03-01        2  ...                 NaN                   NaN   \n",
       "\n",
       "   growth_brent_oil_90d  growth_brent_oil_365d  growth_btc_usd_1d  \\\n",
       "0                   NaN                    NaN                NaN   \n",
       "1                   NaN                    NaN                NaN   \n",
       "2                   NaN                    NaN                NaN   \n",
       "3                   NaN                    NaN                NaN   \n",
       "4                   NaN                    NaN                NaN   \n",
       "\n",
       "   growth_btc_usd_3d  growth_btc_usd_7d  growth_btc_usd_30d  \\\n",
       "0                NaN                NaN                 NaN   \n",
       "1                NaN                NaN                 NaN   \n",
       "2                NaN                NaN                 NaN   \n",
       "3                NaN                NaN                 NaN   \n",
       "4                NaN                NaN                 NaN   \n",
       "\n",
       "   growth_btc_usd_90d  growth_btc_usd_365d  \n",
       "0                 NaN                  NaN  \n",
       "1                 NaN                  NaN  \n",
       "2                 NaN                  NaN  \n",
       "3                 NaN                  NaN  \n",
       "4                 NaN                  NaN  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_parquet(\"D:\\zoomcamp\\myproject\\stock-market-analytics\\module3\\downloadsfchkomj5.part\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tZF13UbOXGF",
    "outputId": "4a18459a-8d10-4d64-f5f0-9d6ee2ddfa5d"
   },
   "outputs": [],
   "source": [
    "GROWTH = [g for g in df_full.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
    "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']\n",
    "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type']\n",
    "TO_PREDICT = [g for g in df_full.keys() if (g.find('future')>=0)]\n",
    "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VgBFjAADfXSp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Garjita\\AppData\\Local\\Temp\\ipykernel_15128\\912909511.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  df_full['ln_volume'] = df_full.Volume.apply(lambda x: np.log(x))\n"
     ]
    }
   ],
   "source": [
    "df_full['ln_volume'] = df_full.Volume.apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lukhBLIcfW8g"
   },
   "outputs": [],
   "source": [
    "# manually defined features\n",
    "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IpRKmVtaf6is"
   },
   "outputs": [],
   "source": [
    "# All Supported Ta-lib indicators: https://github.com/TA-Lib/ta-lib-python/blob/master/docs/funcs.md\n",
    "\n",
    "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
    " 'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
    " 'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
    " 'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
    " 'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
    " 'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
    " 'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
    " 'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
    " 'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncPdBnx13ilm",
    "outputId": "2f988be7-3810-4c1b-e342-ec48a3febb69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical patterns count = 61, examples = ['cdl2crows', 'cdl3blackrows', 'cdl3inside', 'cdl3linestrike', 'cdl3outside']\n"
     ]
    }
   ],
   "source": [
    "TECHNICAL_PATTERNS = [g for g in df_full.keys() if g.find('cdl')>=0]\n",
    "print(f'Technical patterns count = {len(TECHNICAL_PATTERNS)}, examples = {TECHNICAL_PATTERNS[0:5]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ri9F9mIwIuVa",
    "outputId": "1a3aee8b-61e4-455f-b771-28860bb8133b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['growth_future_5d', 'is_positive_growth_5d_future']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS', 'DGS1', 'DGS5', 'DGS10']\n",
    "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO\n",
    "\n",
    "# CHECK: NO OTHER INDICATORS LEFT\n",
    "OTHER = [k for k in df_full.keys() if k not in OHLCV + CATEGORICAL + NUMERICAL + TO_DROP]\n",
    "OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zv_OOrK1ulV",
    "outputId": "f35730f6-379e-45af-8e3c-4afaff6e1546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.Ticker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmIpnwsJLvtI",
    "outputId": "eff90f87-3b42-4e22-ec0a-8ec75d79ebdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182675 entries, 3490 to 5426\n",
      "Columns: 203 entries, Open to ln_volume\n",
      "dtypes: datetime64[ns](3), float64(129), int32(64), int64(5), object(2)\n",
      "memory usage: 239.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# truncated df_full with 25 years of data (and defined growth variables)\n",
    "df = df_full[df_full.Date>='2000-01-01']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pa-AoEDeLX4x"
   },
   "outputs": [],
   "source": [
    "# dummy variables are not generated from Date and numeric variables\n",
    "df.loc[:,'Month'] = df.Month.dt.strftime('%B')\n",
    "df.loc[:,'Weekday'] = df.Weekday.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tuAlw48XKjE5"
   },
   "outputs": [],
   "source": [
    "# Generate dummy variables (no need for bool, let's have int32 instead)\n",
    "dummy_variables = pd.get_dummies(df[CATEGORICAL], dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies names in a list\n",
    "DUMMIES = dummy_variables.keys().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (1 point): Dummies on Month and Week-of-Month\n",
    "Find the ABSOLUTE CORRELATION VALUE of the most correlated dummy with the binary outcome variable is_positive_growth_5d_future?\n",
    "\n",
    "You saw in the correlation analysis and modeling that September and October may be important seasonal months. In this task, we'll go futher and try to generate dummies for Month and Week-of-month (starting from 1). For example, the first week of October should be coded similar to this: 'October_w1'. Once you've generated the new set of variables, find the most correlated (in absolute value) one with is_positive_growth_5d_future and round it to 3 digits after the comma.\n",
    "\n",
    "Suggested path to a solution:\n",
    "\n",
    "[Source] Use this formula to get the week of month for the datetime variable d: (d.day-1)//7+1 Define a new string variable for all month-week_of_month combinations. Append it to the CATEGORICAL features set. You should have 5 variables treated as CATEGORICAL now: 'Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom'. In the end, you should get 115 dummy features, including 60 (=12*5) week_month_of_week dummies. Use pandas.get_dummies() to generate dummies. Use pandas.DataFrame.corr() function (also used in [Code Snippet 1]) to get correlations with is_positive_growth_5d_future, filter out only variables representing the new dummy set, and sort it by absolute values (you can define a new column \"abs_corr\" in the dataframe with correlations), and find the highest value (among the new dummies features set). NOTE: new dummies will be used as features in the next tasks, please leave them in the dataset.\n",
    "\n",
    "**Question 1. [Dummies on Month and Week-of-Month] Top correlation of a new dummy with a boolean prediction variable? (1 point)**\n",
    "\n",
    "- 0.025\n",
    "\n",
    "- 0.035\n",
    "\n",
    "- 0.045\n",
    "\n",
    "- 0.055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dovxcVkk-72S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3490    January_w1\n",
       "3491    January_w1\n",
       "3492    January_w1\n",
       "3493    January_w1\n",
       "3494    January_w1\n",
       "           ...    \n",
       "5422      April_w5\n",
       "5423        May_w1\n",
       "5424        May_w1\n",
       "5425        May_w1\n",
       "5426        May_w1\n",
       "Name: Date, Length: 182675, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 1: define more categorical features, e.g. all combinations for <September+weekday>  (you'll see that September is actually an important dummy in one of the models)\n",
    "week_of_month  = ((df[\"Date\"].dt.day - 1) // 7) + 1\n",
    "month_week_of_month = df[\"Date\"].dt.month_name().str.cat(week_of_month.astype(str), sep=\"_w\")\n",
    "month_week_of_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_week_of_month_dummy = pd.get_dummies(month_week_of_month)\n",
    "correlations = month_week_of_month_dummy.corrwith(df[\"is_positive_growth_5d_future\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "September_w3   -0.034537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations[[correlations.abs().idxmax()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer of Question 1 : 0.035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (2 points): Define new \"hand\" rules on macro and technical indicators variables\n",
    "What is the precision score for the best of the NEW predictions (pred3 or pred4), rounded to 3 digits after the comma?\n",
    "\n",
    "Let's utilize the knowledge from the visualised tree (clf10) (Code Snippet 5: 1.4.4 Visualisation):\n",
    "\n",
    "You're asked to define two new 'hand' rules (leading to 'positive' subtrees):\n",
    "\n",
    "pred3_manual_gdp_fastd: (gdppot_us_yoy <= 0.027) & (fastd >= 0.251) pred4_manual_gdp_wti_oil: (gdppot_us_yoy >= 0.027) & (growth_wti_oil_30d <= 1.005) Extend the Code Snippet 3 (Manual \"hand rule\" predictions): Calculate and add new rules (pred3 and pred4) to the dataframe.You should notice that one of the predictions doesn't have any positive predictions on TEST dataset (while it has many on TRAIN+VALIDATION).\n",
    "\n",
    "Debug: check in the new_df and the original dataset/data generation process that we didn't make any mistakes during the data transformation step.\n",
    "\n",
    "Explain why this can happen even if there are no errors in the data features.\n",
    "\n",
    "As a result, write down the precision score for the remaining predictor (round to three decimal points). E.g. if you have 0.57897, your answer should be 0.579.\n",
    "\n",
    "**Question 2. [Define new 'hand' rules] What's the precision score for the best new rule? (2 points)**\n",
    "\n",
    "- 0.575\n",
    "\n",
    "- 0.591\n",
    "\n",
    "- 0.612\n",
    "\n",
    "- 0.555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_variables = pd.concat([dummy_variables, month_week_of_month_dummy.astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzzG2DfZKpFn",
    "outputId": "bb7f7841-741b-4a79-9e19-fa23170df06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182675 entries, 3490 to 5426\n",
      "Columns: 115 entries, Month_April to September_w5\n",
      "dtypes: int32(115)\n",
      "memory usage: 81.5 MB\n"
     ]
    }
   ],
   "source": [
    "dummy_variables.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sxLHnVE3RaaU"
   },
   "outputs": [],
   "source": [
    "# get dummies names in a list\n",
    "DUMMIES = dummy_variables.keys().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "j0e65F71Kl15"
   },
   "outputs": [],
   "source": [
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df_with_dummies = pd.concat([df, dummy_variables], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Qim1MIwUWE9",
    "outputId": "ced7556a-1de9-4cbf-abbd-4e79b8235501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182675 entries, 3490 to 5426\n",
      "Columns: 299 entries, growth_1d to September_w5\n",
      "dtypes: float64(121), int32(177), int64(1)\n",
      "memory usage: 294.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_with_dummies[NUMERICAL+DUMMIES].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "loo6ktrtvKrn"
   },
   "outputs": [],
   "source": [
    "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into three buckets based on the temporal order of the 'Date' column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame to split.\n",
    "        min_date (str or Timestamp): Minimum date in the DataFrame.\n",
    "        max_date (str or Timestamp): Maximum date in the DataFrame.\n",
    "        train_prop (float): Proportion of data for training set (default: 0.6).\n",
    "        val_prop (float): Proportion of data for validation set (default: 0.2).\n",
    "        test_prop (float): Proportion of data for test set (default: 0.2).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The input DataFrame with a new column 'split' indicating the split for each row.\n",
    "    \"\"\"\n",
    "    # Define the date intervals\n",
    "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
    "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
    "\n",
    "    # Assign split labels based on date ranges\n",
    "    split_labels = []\n",
    "    for date in df['Date']:\n",
    "        if date <= train_end:\n",
    "            split_labels.append('train')\n",
    "        elif date <= val_end:\n",
    "            split_labels.append('validation')\n",
    "        else:\n",
    "            split_labels.append('test')\n",
    "\n",
    "    # Add 'split' column to the DataFrame\n",
    "    df['split'] = split_labels\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G0gVQMUEyNIc"
   },
   "outputs": [],
   "source": [
    "min_date_df = df_with_dummies.Date.min()\n",
    "max_date_df = df_with_dummies.Date.max()\n",
    "\n",
    "df_with_dummies = temporal_split(df_with_dummies,\n",
    "                                 min_date = min_date_df,\n",
    "                                 max_date = max_date_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-aPYFprylhp",
    "outputId": "ab801650-817c-4845-c240-617d027cccdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train         0.675834\n",
       "test          0.163290\n",
       "validation    0.160876\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_dummies['split'].value_counts()/len(df_with_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c2qCynDQBMpV"
   },
   "outputs": [],
   "source": [
    "# remove the \"segmentation\" problem (warning message on df performance after many joins and data transformations)\n",
    "new_df = df_with_dummies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZtHf2IDPf_8",
    "outputId": "0667fd51-75a3-46ab-af5d-336d3a46d1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 182675 entries, 3490 to 5426\n",
      "Columns: 319 entries, Open to split\n",
      "dtypes: datetime64[ns](2), float64(129), int32(178), int64(5), object(5)\n",
      "memory usage: 321.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Full dataframe (transformed and truncated to 25 years)\n",
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Ujwk8Rpxi5jQ"
   },
   "outputs": [],
   "source": [
    "# generate manual predictions\n",
    "# Let's label all prediction features with prefix \"pred\"\n",
    "new_df['pred0_manual_cci'] = (new_df.cci>200).astype(int)\n",
    "new_df['pred1_manual_prev_g1'] = (new_df.growth_1d>1).astype(int)\n",
    "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_1d'] > 1) & (new_df['growth_snp500_1d'] > 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5522010081688141, 0.5374581350255596)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[\"pred3_manual_gdp_fastd\"] = (new_df[\"gdppot_us_yoy\"] <= 0.027) & (new_df[\"fastd\"] >= 0.251)\n",
    "new_df[\"pred4_manual_gpd_wti_oil\"] = (new_df[\"gdppot_us_yoy\"] >= 0.027) & (new_df[\"growth_wti_oil_30d\"] <= 1.005)\n",
    "\n",
    "acc_3 = (new_df[\"pred3_manual_gdp_fastd\"] * new_df[\"is_positive_growth_5d_future\"]).sum() / new_df[\"pred3_manual_gdp_fastd\"].sum()\n",
    "acc_4 = (new_df[\"pred4_manual_gpd_wti_oil\"] * new_df[\"is_positive_growth_5d_future\"]).sum() / new_df[\"pred4_manual_gpd_wti_oil\"].sum()\n",
    "\n",
    "acc_3, acc_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5552947488431359, 0.5374581350255596)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering only test\n",
    "test_data = new_df[new_df[\"split\"] == \"test\"]\n",
    "acc_3 = (test_data[\"pred3_manual_gdp_fastd\"] * test_data[\"is_positive_growth_5d_future\"]).sum() / test_data[\"pred3_manual_gdp_fastd\"].sum()\n",
    "# pred4 doesnt predict 1 for any value in the test partition.\n",
    "# acc_4 = (test_data[\"pred4_manual_gpd_wti_oil\"] * test_data[\"is_positive_growth_5d_future\"]).sum() / test_data[\"pred4_manual_gpd_wti_oil\"].sum()\n",
    "\n",
    "acc_3, acc_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqYgFqGLA-Ar",
    "outputId": "beacf464-19eb-4d69-82c6-7173aaa3273f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pred0_manual_cci', 'pred1_manual_prev_g1',\n",
       "       'pred2_manual_prev_g1_and_snp', 'pred3_manual_gdp_fastd',\n",
       "       'pred4_manual_gpd_wti_oil'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTIONS = new_df.columns[new_df.columns.str.startswith(\"pred\")]\n",
    "PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-hh7Gd_H_AU3"
   },
   "outputs": [],
   "source": [
    "# generate columns is_correct_\n",
    "for pred in PREDICTIONS:\n",
    "  part1 = pred.split('_')[0] # first prefix before '_'\n",
    "  new_df[f'is_correct_{part1}'] =  (new_df[pred] == new_df.is_positive_growth_5d_future).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elm6SLsVCX8L",
    "outputId": "8abe47b6-454d-43ef-a57d-d11adc4bc54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_correct_pred0',\n",
       " 'is_correct_pred1',\n",
       " 'is_correct_pred2',\n",
       " 'is_correct_pred3',\n",
       " 'is_correct_pred4']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IS_CORRECT dataset\n",
    "IS_CORRECT =  [k for k in new_df.keys() if k.startswith('is_correct_')]\n",
    "IS_CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b8gV4iXC9HV",
    "outputId": "adaa154c-1075-40de-956c-46808446363f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction column:pred0_manual_cci , is_correct_column: is_correct_pred0\n",
      "is_correct_pred0\n",
      "1    455\n",
      "0    344\n",
      "Name: count, dtype: int64\n",
      "is_correct_pred0\n",
      "1    0.569462\n",
      "0    0.430538\n",
      "Name: count, dtype: float64\n",
      "---------\n",
      "Prediction column:pred1_manual_prev_g1 , is_correct_column: is_correct_pred1\n",
      "is_correct_pred1\n",
      "1    8621\n",
      "0    6980\n",
      "Name: count, dtype: int64\n",
      "is_correct_pred1\n",
      "1    0.552593\n",
      "0    0.447407\n",
      "Name: count, dtype: float64\n",
      "---------\n",
      "Prediction column:pred2_manual_prev_g1_and_snp , is_correct_column: is_correct_pred2\n",
      "is_correct_pred2\n",
      "1    5726\n",
      "0    4729\n",
      "Name: count, dtype: int64\n",
      "is_correct_pred2\n",
      "1    0.547681\n",
      "0    0.452319\n",
      "Name: count, dtype: float64\n",
      "---------\n",
      "Prediction column:pred3_manual_gdp_fastd , is_correct_column: is_correct_pred3\n",
      "is_correct_pred3\n",
      "1    16560\n",
      "0    13262\n",
      "Name: count, dtype: int64\n",
      "is_correct_pred3\n",
      "1    0.555295\n",
      "0    0.444705\n",
      "Name: count, dtype: float64\n",
      "---------\n",
      "Prediction column:pred4_manual_gpd_wti_oil , is_correct_column: is_correct_pred4\n",
      "Series([], Name: count, dtype: int64)\n",
      "Series([], Name: count, dtype: float64)\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# define \"Precision\" for ALL predictions on a Test dataset (~4 last years of trading)\n",
    "for i,column in enumerate(IS_CORRECT):\n",
    "  prediction_column = PREDICTIONS[i]\n",
    "  is_correct_column = column\n",
    "  filter = (new_df.split=='test') & (new_df[prediction_column]==1)\n",
    "  print(f'Prediction column:{prediction_column} , is_correct_column: {is_correct_column}')\n",
    "  print(new_df[filter][is_correct_column].value_counts())\n",
    "  print(new_df[filter][is_correct_column].value_counts()/len(new_df[filter]))\n",
    "\n",
    "  print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer of Question 2 : 0.555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (1 point): Unique correct predictions from a 10-levels deep Decision Tree Classifier (pred5_clf_10)\n",
    "What is the total number of records in the TEST dataset when the new prediction pred5_clf_10 is better than all 'hand' rules (pred0..pred4)?\n",
    "\n",
    "NOTE: please include random_state=42 to Decision Tree Classifier init function (line clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)) to ensure everyone gets the same results.\n",
    "\n",
    "Suggested solution:\n",
    "\n",
    "Step1: Rewrite the '1.4.3 Inference for a decision tree' piece for the Decision Tree Classifier with max_depth=10 (clf_10), so that you fit the model on TRAIN+VALIDATION sets (unchanged from the lecture), but predict on the whole set X_all (to be able to define a new column 'pred5_clf_10' in the dataframe new_df). Here is the link with explanation. It will solve the problem in 1.4.5 when predictions were made only for Test dataset and couldn't be easily joined with the full dataset.\n",
    "\n",
    "Step2: Once you have it, define a new column 'only_pred5_is_correct' similar to 'hand' prediction rules with several conditions: is_positive_growth_5d_future AND is_correct_pred5 should be equal 1, while all other predictions is_correct_pred0..is_correct_pred4 should be equal to 0.\n",
    "\n",
    "Step3: Convert 'only_pred5_is_correct' column from bool to int, and find how many times it is equal to 1 in the TEST set. Write down this as an answer.\n",
    "\n",
    "ADVANCED: define a function that can be applied to the whole row of predictions (a few examples of pandas-apply-row-functions) and can find whether some prediction 'predX' (where X is one of the predictions) is uniquely correct. It should work even if there are 100 predictions available, so that you don't define manually the condition for 'predX'.\n",
    "\n",
    "**Question 3. [Unique correct predictions for pred5_clf_10] Wha'ts the total number of records of 'unique correctness' on TEST? (1 point)**\n",
    "\n",
    "- 1\n",
    "\n",
    "- 5\n",
    "\n",
    "- 10\n",
    "\n",
    "- 15\n",
    "\n",
    "- 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "lMHrM1sdLdYc"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oYKW8lodlM7"
   },
   "source": [
    "### 1.4.1) Define dataframes AND perform data cleaning\n",
    "* define X_train (dataframe), X_test (dataframe), y_train (series), y_test (series)\n",
    "* replace +-inf. with 0\n",
    "* fill NaNs with 0 (you can drop it too, but will loose a lot of data in our case\n",
    "* remove 1-2% outliers (in each dimension, or only in variable to_predict :: we won't use it for a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "nNjsv3RtNjCu"
   },
   "outputs": [],
   "source": [
    "# Decision Tree doesn't like too large and inf. values\n",
    "import numpy as np\n",
    "\n",
    "def remove_infinite_values(X):\n",
    "    \"\"\"\n",
    "    Remove infinite values from the input array.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input array (NumPy array or array-like)\n",
    "\n",
    "    Returns:\n",
    "    - Array with infinite values removed\n",
    "    \"\"\"\n",
    "    return X[np.isfinite(X).all(axis=1)]\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X is your input data\n",
    "# filtered_X = remove_infinite_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoiZYkfhQa_g",
    "outputId": "e45ab692-4426-4162-d32c-3c71b743051c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: X_train (152846, 302),  X_test (29829, 302)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets based on the split date\n",
    "features_list = NUMERICAL+DUMMIES\n",
    "to_predict = 'is_positive_growth_5d_future'\n",
    "\n",
    "train_df = new_df[new_df.split.isin(['train','validation'])].copy(deep=True)\n",
    "test_df = new_df[new_df.split.isin(['test'])].copy(deep=True)\n",
    "\n",
    "# ONLY numerical Separate features and target variable for training and testing sets\n",
    "# need Date and Ticker later when merging predictions to the dataset\n",
    "X_train = train_df[features_list+[to_predict,'Date','Ticker']]\n",
    "X_test = test_df[features_list+[to_predict,'Date','Ticker']]\n",
    "\n",
    "print(f'length: X_train {X_train.shape},  X_test {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46GYMy7KRUB3",
    "outputId": "74d00099-fba8-4417-e778-6e16e0241c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: X_train_imputed (152846, 302),  X_test_imputed (29829, 302)\n"
     ]
    }
   ],
   "source": [
    "# Can't have +-inf values . E.g. ln(volume)=-inf when volume==0 => substitute with 0\n",
    "\n",
    "# Disable SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Need to fill NaNs somehow\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "\n",
    "print(f'length: X_train_imputed {X_train.shape},  X_test_imputed {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "GiJKy6vPWB19"
   },
   "outputs": [],
   "source": [
    "# you may want to remove 1-2% outliers based on percentile ==> not used here in Decision Trees\n",
    "def remove_outliers_percentile(X, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"\n",
    "    Remove outliers from the input array based on percentiles.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input array (NumPy array or array-like)\n",
    "    - lower_percentile: Lower percentile threshold (float, default=1)\n",
    "    - upper_percentile: Upper percentile threshold (float, default=99)\n",
    "\n",
    "    Returns:\n",
    "    - Array with outliers removed\n",
    "    \"\"\"\n",
    "    lower_bound = np.percentile(X, lower_percentile, axis=0)\n",
    "    upper_bound = np.percentile(X, upper_percentile, axis=0)\n",
    "    mask = np.logical_and(np.all(X >= lower_bound, axis=1), np.all(X <= upper_bound, axis=1))\n",
    "    return X[mask]\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X is your input data\n",
    "# filtered_X = remove_outliers_percentile(X, lower_percentile=1, upper_percentile=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8-NNrhAKWXr8"
   },
   "outputs": [],
   "source": [
    "X_train_imputed = X_train # we won't use outliers removal to save more data to train: remove_outliers_percentile(X_train)\n",
    "X_test_imputed = X_test # we won't use outliers removal to save more data to test: remove_outliers_percentile(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBXvMVKWWgSc",
    "outputId": "5424a261-b9af-4f9d-d5d9-c38753440ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: X_train_imputed (152846, 302),  X_test_imputed (29829, 302)\n"
     ]
    }
   ],
   "source": [
    "# same shape\n",
    "print(f'length: X_train_imputed {X_train_imputed.shape},  X_test_imputed {X_test_imputed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "E6A_zhDLW0aC"
   },
   "outputs": [],
   "source": [
    "y_train = X_train_imputed[to_predict]\n",
    "y_test = X_test_imputed[to_predict]\n",
    "\n",
    "# remove y_train, y_test from X_ dataframes\n",
    "del X_train_imputed[to_predict]\n",
    "del X_test_imputed[to_predict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUGSkY7yeO5F"
   },
   "source": [
    "### 1.4.2 Estimation of a Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "tsSxJEireSeW"
   },
   "outputs": [],
   "source": [
    "# INPUTS:\n",
    "# X_train_imputed : CLEAN dataFrame with only numerical features (train+validation periods)\n",
    "# X_test_imputed : CLEAN dataFrame with only numerical features (test periods)\n",
    "\n",
    "# y_train : true values for the train period\n",
    "# y_test  : true values for the test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "QcJAw5w9R7pA"
   },
   "outputs": [],
   "source": [
    "# estimation/fit function (using dataframe of features X and what to predict y) --> optimising total accuracy\n",
    "# max_depth is hyperParameter\n",
    "def fit_decision_tree(X, y, max_depth=20):\n",
    "# Initialize the Decision Tree Classifier\n",
    "  clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "\n",
    "  # Fit the classifier to the training data\n",
    "  clf.fit(X, y)\n",
    "  return clf, X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ClqSfId-gbMW",
    "outputId": "3fb41805-a03f-479d-94ed-b3262402c261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.86 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_10, train_columns = fit_decision_tree(X=X_train_imputed.drop(['Date','Ticker'],axis=1),\n",
    "                           y=y_train,\n",
    "                           max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "x74N7Brb-IAm"
   },
   "outputs": [],
   "source": [
    "# TODO 3: TRAIN only on train dataset, experiment with trees with depth 1..20 --> find the best one on VALID dataset\n",
    "#       for the \"best\" tree model: find precision on the TEST set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QbUrS7Ygm2G"
   },
   "source": [
    "### 1.4.3 Inference for a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "csUq1CWISRCe"
   },
   "outputs": [],
   "source": [
    "def predict_decision_tree(clf:DecisionTreeClassifier, df_X:pd.DataFrame, y_true: pd.Series):\n",
    "  # Predict the target variable on the test data\n",
    "  y_pred = clf.predict(df_X)\n",
    "\n",
    "  max_depth = clf.tree_.max_depth\n",
    "  # Print the maximum depth\n",
    "  print(\"Maximum depth of the decision tree:\", max_depth)\n",
    "\n",
    "  # Calculate the accuracy/precision of the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  precision = precision_score(y_test, y_pred)\n",
    "  print(f'Accuracy ={accuracy}, precision = {precision}')\n",
    "\n",
    "  # resulting df\n",
    "  result_df = pd.concat([df_X, y_true, pd.Series(y_pred, index=df_X.index, name='pred_')], axis=1)\n",
    "\n",
    "  return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "84F-Mk1P2sGb"
   },
   "outputs": [],
   "source": [
    "# Feautures importance function to predict future returns (based on the classifier)\n",
    "# get feature importance from 'clf' (classifier) and 'train_columns' (column names)\n",
    "\n",
    "def get_importances(clf, train_columns):\n",
    "  # Assuming clf is your trained DecisionTreeClassifier\n",
    "  feature_importance = clf.feature_importances_\n",
    "\n",
    "  # Assuming X_train is your training features\n",
    "  feature_names = train_columns\n",
    "\n",
    "  # Create a DataFrame to store feature importance\n",
    "  feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "\n",
    "  # Sort the DataFrame by importance in descending order\n",
    "  feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "  # Print or display the feature importance DataFrame\n",
    "  # print(feature_importance_df)\n",
    "  return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "z3scA_5KnLbZ"
   },
   "outputs": [],
   "source": [
    "# TODO 4: JOIN predictions with the original dataframe (define a new column):\n",
    "#  so, that there are columns pred_tree_clf10 AND pred_tree_clf20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = clf_10.predict(X_test_imputed.drop(['Date','Ticker'],axis=1))\n",
    "tp_series = pd.Series(test_pred, dtype=int)\n",
    "tp_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = new_df[\"split\"] == \"test\"\n",
    "new_df.loc[test_mask, \"pred5_clf_10\"] = tp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0_to_4 = new_df.loc[test_mask, new_df.columns.str.contains(r\"^pred[0-4]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_all_wrong = (pred0_to_4.values != new_df.loc[test_mask, to_predict].values[:, np.newaxis]).all(axis=1)\n",
    "pred_5_correct = new_df.loc[test_mask, to_predict].values == new_df.loc[test_mask, \"pred5_clf_10\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(manual_all_wrong & pred_5_correct).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred0_manual_cci</th>\n",
       "      <th>pred1_manual_prev_g1</th>\n",
       "      <th>pred2_manual_prev_g1_and_snp</th>\n",
       "      <th>pred3_manual_gdp_fastd</th>\n",
       "      <th>pred4_manual_gpd_wti_oil</th>\n",
       "      <th>pred5_clf_10</th>\n",
       "      <th>is_positive_growth_5d_future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred0_manual_cci  pred1_manual_prev_g1  pred2_manual_prev_g1_and_snp  \\\n",
       "4                 0                     0                             0   \n",
       "\n",
       "   pred3_manual_gdp_fastd  pred4_manual_gpd_wti_oil  pred5_clf_10  \\\n",
       "4                   False                     False           1.0   \n",
       "\n",
       "   is_positive_growth_5d_future  \n",
       "4                             1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = new_df.columns[new_df.columns.str.contains(r\"^pred\")].to_list()\n",
    "new_df.loc[test_mask, pred_cols + [to_predict]][manual_all_wrong & pred_5_correct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer of Question 3 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((152846, 299), (152846,), (29829, 299), (29829,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLY numerical Separate features and target variable for training and testing sets\n",
    "# need Date and Ticker later when merging predictions to the dataset\n",
    "X_train = new_df.loc[new_df[\"split\"].isin(['train','validation']), features_list]\n",
    "y_train = new_df.loc[new_df[\"split\"].isin(['train','validation']), to_predict]\n",
    "X_test = new_df.loc[new_df[\"split\"] == \"test\", features_list]\n",
    "y_test = new_df.loc[new_df[\"split\"] == \"test\", to_predict]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Need to fill NaNs somehow\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1\n",
      "0.555\t0.555\n",
      "max_depth=2\n",
      "0.555\t0.555\n",
      "max_depth=3\n",
      "0.555\t0.555\n",
      "max_depth=4\n",
      "0.555\t0.555\n",
      "max_depth=5\n",
      "0.556\t0.555\n",
      "max_depth=6\n",
      "0.568\t0.571\n",
      "max_depth=7\n",
      "0.565\t0.568\n",
      "max_depth=8\n",
      "0.565\t0.568\n",
      "max_depth=9\n",
      "0.567\t0.570\n",
      "max_depth=10\n",
      "0.557\t0.565\n",
      "max_depth=11\n",
      "0.552\t0.567\n",
      "max_depth=12\n",
      "0.547\t0.572\n",
      "max_depth=13\n",
      "0.549\t0.571\n",
      "max_depth=14\n",
      "0.547\t0.584\n",
      "max_depth=15\n",
      "0.560\t0.586\n",
      "max_depth=16\n",
      "0.540\t0.572\n",
      "max_depth=17\n",
      "0.537\t0.577\n",
      "max_depth=18\n",
      "0.532\t0.568\n",
      "max_depth=19\n",
      "0.527\t0.564\n",
      "max_depth=20\n",
      "0.528\t0.573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.55519796, 0.55536558, 0.55519796, 0.55526501, 0.55560025,\n",
       "        0.56776962, 0.56502062, 0.56502062, 0.56699856, 0.5570418 ,\n",
       "        0.5516779 , 0.54658219, 0.54859365, 0.54705153, 0.55972376,\n",
       "        0.54024607, 0.5368601 , 0.53169734, 0.52650106, 0.52797613]),\n",
       " array([0.55519796, 0.55529475, 0.55519796, 0.55523519, 0.55546233,\n",
       "        0.57117355, 0.56839335, 0.56839335, 0.56999117, 0.56527843,\n",
       "        0.56703676, 0.57185459, 0.57073015, 0.5844969 , 0.58644341,\n",
       "        0.5720942 , 0.57668677, 0.56821053, 0.56379247, 0.57304363]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = np.zeros((20, ))\n",
    "precisions = np.zeros((20, ))\n",
    "for i, max_depth in enumerate(range(1, 21)):\n",
    "    print(f\"{max_depth=}\")\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracies[i] = accuracy_score(y_test, y_pred)\n",
    "    precisions[i] = precision_score(y_test, y_pred)\n",
    "    print(f\"{accuracies[i]:.3f}\\t{precisions[i]:.3f}\")\n",
    "\n",
    "accuracies, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1, 21)[precisions.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=12, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=12, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=12, random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=12, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>pred2_manual_prev_g1_and_snp</th>\n",
       "      <th>pred3_manual_gdp_fastd</th>\n",
       "      <th>pred4_manual_gpd_wti_oil</th>\n",
       "      <th>is_correct_pred0</th>\n",
       "      <th>is_correct_pred1</th>\n",
       "      <th>is_correct_pred2</th>\n",
       "      <th>is_correct_pred3</th>\n",
       "      <th>is_correct_pred4</th>\n",
       "      <th>pred5_clf_10</th>\n",
       "      <th>pred6_best_clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1571996.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3748847.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4079696.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2614667.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>3479.399902</td>\n",
       "      <td>3496.000000</td>\n",
       "      <td>3425.000000</td>\n",
       "      <td>3427.750000</td>\n",
       "      <td>3427.750000</td>\n",
       "      <td>3375099.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "5426  3479.399902  3496.000000  3425.000000  3427.750000  3427.750000   \n",
       "\n",
       "         Volume Ticker  Year  Month Weekday  ... pred2_manual_prev_g1_and_snp  \\\n",
       "5422  1571996.0  LT.NS  2024  April       1  ...                            0   \n",
       "5423  3748847.0  LT.NS  2024    May       3  ...                            1   \n",
       "5424  4079696.0  LT.NS  2024    May       4  ...                            0   \n",
       "5425  2614667.0  LT.NS  2024    May       0  ...                            0   \n",
       "5426  3375099.0  LT.NS  2024    May       1  ...                            0   \n",
       "\n",
       "      pred3_manual_gdp_fastd  pred4_manual_gpd_wti_oil  is_correct_pred0  \\\n",
       "5422                    True                     False                 1   \n",
       "5423                    True                     False                 1   \n",
       "5424                    True                     False                 1   \n",
       "5425                    True                     False                 1   \n",
       "5426                    True                     False                 1   \n",
       "\n",
       "      is_correct_pred1  is_correct_pred2  is_correct_pred3  is_correct_pred4  \\\n",
       "5422                 1                 1                 0                 1   \n",
       "5423                 0                 0                 0                 1   \n",
       "5424                 1                 1                 0                 1   \n",
       "5425                 1                 1                 0                 1   \n",
       "5426                 1                 1                 0                 1   \n",
       "\n",
       "      pred5_clf_10  pred6_best_clf  \n",
       "5422           1.0               1  \n",
       "5423           1.0               1  \n",
       "5424           1.0               1  \n",
       "5425           1.0               1  \n",
       "5426           1.0               1  \n",
       "\n",
       "[5 rows x 331 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "pred6_best_clf = np.concatenate([train_pred, test_pred])\n",
    "new_df[\"pred6_best_clf\"] = pred6_best_clf\n",
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer of Question 4 : 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
